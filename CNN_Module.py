# -*- coding: utf-8 -*-
"""Final_try-Copy1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FBfJ2ADu4_TVx8kPc5eBwjthVE3miyye

standard_deviation_image
deviation_from_mean
get_DistanceFromOD_data
count_ones
get_average_intensity
get_average_hue
get_average_saturation
get_SD_data
get_HUE_data
get_saturation_data
get_INTENSITY_data
get_EDGE_data
get_RED_data
get_GREEN_data
line_of_symmetry
identify_OD_bv_density
calculate_entropy
edge_pixel_image
"""

import numpy as np
import cv2
from numba import jit
import os
from matplotlib import pyplot as plt
import math
import csv
from sklearn import preprocessing
import os
import csv
import time
import math
from PIL import Image, ImageFilter

img =cv2.imread("C:/Users/PB/Desktop/imagep/r3.jpg")

hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)

# Define lower and uppper limits of what we call "brown"
lower_black = np.array([0,0,0], dtype = "uint16")
upper_black = np.array([70,70,70], dtype = "uint16")
black_mask = cv2.inRange(img, lower_black, upper_black)


img[black_mask>0] = [106,108,110]

# Change image to red where we found brown
f2 = img[:,:,1]#bue
f3 = img[:,:,2]#green

#width = img.shape[1] 7198
#channels = img.shape[2] 3

clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
clahe_output = clahe.apply(f2)

gaussian_3 = cv2.GaussianBlur(clahe_output, (9,9), 10.0)
unsharp_image = cv2.addWeighted(clahe_output, 1.5, gaussian_3, -0.5, 0, clahe_output)

newfin = cv2.dilate(unsharp_image, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations=1)
edge_candidates = cv2.erode(newfin, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations=1)

#ret,img1 = cv2.threshold(edge_candidates, 127, 255, cv2.THRESH_BINARY)



#ret,th1 = cv2.threshold(edge_candidates,127,255,cv2.THRESH_BINARY)
#edge_candidates = cv2.erode(th1, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations=1)



plt.imshow(img,'gray')
plt.show()
plt.imshow(edge_candidates,'gray')
plt.show()

from __future__ import print_function
from builtins import input
import cv2 as cv
import numpy as np
import argparse
from skimage.filters import threshold_local,threshold_otsu,threshold_yen
from PIL import Image
import PIL

from skimage.filters import sobel, roberts,prewitt

new_image = np.zeros(edge_candidates.shape, edge_candidates.dtype)
alpha = 1 # Simple contrast control
beta = 25 # Simple brightness control

#new_image(i,j) = alpha*image(i,j) + beta
# Instead of these 'for' loops we could have used simply:
new_image = cv2.convertScaleAbs(edge_candidates, alpha=alpha, beta=beta)
# but we wanted to show you how to access the pixels
#ret, thresh = cv.threshold(new_image,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)

median = cv2.medianBlur(new_image, 5)
#newfin = cv2.dilate(unsharp_image, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations=1)
#newfin = cv2.erode(newfin, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations=1)
img_array = cv2.bitwise_not(median)
thresh =threshold_otsu(img_array)
output1 =img_array>thresh
#final= cv2.bitwise_not(binary)
adaptive= threshold_local(output1,block_size=15, offset=1)
adaptive.astype(np.uint8)
print(adaptive.shape)
print(adaptive.dtype)
plt.imshow(f2,'gray')
plt.show()
plt.imshow(output1,'gray')
plt.show()

print(adaptive.shape)
print(adaptive.dtype)


cv2.imwrite('C:/Users/PB/Desktop/imagep/2.png', 255*adaptive)

final = (255-adaptive)
plt.imshow(final,'gray')
plt.show()

import imageio
from skimage import img_as_ubyte

img4 = img_as_ubyte(adaptive)
print(img.dtype)
plt.imshow(adaptive,'gray')
plt.show()
imageio.imwrite('C:/Users/PB/Desktop/imagep/7.png', 255*final)



